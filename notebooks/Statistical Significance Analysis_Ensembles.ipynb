{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c42c293",
   "metadata": {},
   "source": [
    "\n",
    "# Statistical Significance Analysis\n",
    "\n",
    "This notebook performs statistical testing and uncertainty estimation on per-fold results across multiple ensemble models.\n",
    "\n",
    "**Workflow**\n",
    "1. Input: per-fold `R2` and `MSE` for each model.\n",
    "2. Normality (per model on `R2`): Shapiro–Wilk.\n",
    "3. Homogeneity of variances (across models on `R2`): Levene's test.\n",
    "4. One-way ANOVA on `R2` to assess differences among models.\n",
    "5. Post-hoc pairwise comparisons on `R2`: Tukey HSD, plus compact letter display (CLD).\n",
    "6. Bootstrap confidence intervals for the mean `MSE` per model.\n",
    "7. Outputs: summary table (`R2` mean/SD, CLD group, mean `MSE` and CI), ANOVA table, and figures (bar chart with CLD, bootstrap histograms).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0bdf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import shapiro, levene\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# -------------------\n",
    "# Configuration\n",
    "# -------------------\n",
    "# CSV with columns: model, fold, R2, MSE\n",
    "METRICS_CSV = None  # e.g., \"statsig_inputs/per_fold_metrics.csv\"\n",
    "\n",
    "# Model names must match the \"model\" column values\n",
    "MODEL_NAMES = [\n",
    "    \"LightGBM+CatBoost\",\n",
    "    \"GradientBoosting+XGBoost\",\n",
    "    \"RandomForest+HistGB\",\n",
    "    \"RandomForest+SVM\",\n",
    "    \"MLP+KNN\",\n",
    "    \"SVM+PolynomialReg\",\n",
    "    \"Ridge+BayesianRidge\",\n",
    "]\n",
    "\n",
    "# Bootstrap settings\n",
    "CI_LEVEL = 0.95               # e.g., 0.90 / 0.95 / 0.99\n",
    "ALPHA = 1.0 - CI_LEVEL\n",
    "BOOTSTRAP_N = 10_000          # number of resamples\n",
    "\n",
    "# Outputs\n",
    "OUT_DIR = \"statsig_outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad13580",
   "metadata": {},
   "source": [
    "\n",
    "## Input schema\n",
    "CSV must contain (one row per fold per model):\n",
    "```\n",
    "model,fold,R2,MSE\n",
    "LightGBM+CatBoost,1,0.882,0.119\n",
    "...\n",
    "Ridge+BayesianRidge,5,0.640,0.362\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_metrics_from_csv(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    expected = {\"model\",\"fold\",\"R2\",\"MSE\"}\n",
    "    if not expected.issubset(df.columns):\n",
    "        raise ValueError(f\"CSV must contain columns: {expected}\")\n",
    "    df[\"model\"] = pd.Categorical(df[\"model\"], categories=MODEL_NAMES, ordered=True)\n",
    "    df = df.sort_values([\"model\",\"fold\"]).reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compact_letter_display_from_tukey(tukey_res, model_order: List[str]) -> Dict[str,str]:\n",
    "    \"\"\"Build compact letter display (CLD) from Tukey HSD results.\n",
    "    Models sharing a letter are not significantly different at the chosen alpha level.\n",
    "    \"\"\"\n",
    "    names = tukey_res.groupsunique.tolist()\n",
    "    reject = tukey_res.reject  # True => significant difference\n",
    "    pairs = list(zip(tukey_res._multicomp.pairindices[0], tukey_res._multicomp.pairindices[1]))\n",
    "    # adjacency for \"not significantly different\"\n",
    "    adj = {n: set() for n in names}\n",
    "    for (i,j), r in zip(pairs, reject):\n",
    "        a, b = names[i], names[j]\n",
    "        if not r:\n",
    "            adj[a].add(b); adj[b].add(a)\n",
    "    # greedy letter assignment\n",
    "    groups = {m: set() for m in names}\n",
    "    remaining = set(names)\n",
    "    letter_idx = 0\n",
    "    while remaining:\n",
    "        letter = chr(ord('a') + letter_idx)\n",
    "        this_group = set()\n",
    "        for m in list(remaining):\n",
    "            if all((n not in this_group) for n in adj[m] if n in remaining):\n",
    "                this_group.add(m)\n",
    "        for m in this_group:\n",
    "            groups[m].add(letter)\n",
    "        remaining -= this_group\n",
    "        letter_idx += 1\n",
    "    return {m: \"\".join(sorted(groups.get(m, set()))) for m in model_order}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e6f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_statsig_pipeline(df_metrics: pd.DataFrame, ci_level: float = CI_LEVEL, bootstrap_n: int = BOOTSTRAP_N):\n",
    "    assert 0 < ci_level < 1\n",
    "    alpha = 1.0 - ci_level\n",
    "\n",
    "    df = df_metrics.copy()\n",
    "    df[\"model\"] = pd.Categorical(df[\"model\"], categories=MODEL_NAMES, ordered=True)\n",
    "\n",
    "    # Shapiro–Wilk (R2 per model)\n",
    "    shapiro_rows = []\n",
    "    for m in MODEL_NAMES:\n",
    "        vals = df.loc[df[\"model\"] == m, \"R2\"].dropna().values\n",
    "        if len(vals) < 3:\n",
    "            W, p = np.nan, np.nan\n",
    "        else:\n",
    "            W, p = shapiro(vals)\n",
    "        shapiro_rows.append({\"model\": m, \"W\": W, \"p_value\": p})\n",
    "    shapiro_df = pd.DataFrame(shapiro_rows)\n",
    "\n",
    "    # Levene (R2 across models)\n",
    "    r2_groups = [df.loc[df[\"model\"] == m, \"R2\"].dropna().values for m in MODEL_NAMES]\n",
    "    lev_stat, lev_p = levene(*r2_groups)\n",
    "    levene_df = pd.DataFrame([{\"statistic\": lev_stat, \"p_value\": lev_p, \"k_groups\": len(MODEL_NAMES)}])\n",
    "\n",
    "    # One-way ANOVA (R2)\n",
    "    anova_model = ols('R2 ~ C(model)', data=df).fit()\n",
    "    anova_table = sm.stats.anova_lm(anova_model, typ=2).rename(\n",
    "        index={\"C(model)\":\"Between Groups\",\"Residual\":\"Within Groups\"}\n",
    "    )\n",
    "    anova_table = anova_table.rename(columns={\"sum_sq\":\"SS\",\"mean_sq\":\"MS\",\"PR(>F)\":\"p_value\"})\n",
    "    total_row = pd.DataFrame([{\n",
    "        \"SS\": anova_table[\"SS\"].sum(),\n",
    "        \"df\": anova_table[\"df\"].sum(),\n",
    "        \"MS\": np.nan, \"F\": np.nan, \"p_value\": np.nan\n",
    "    }], index=[\"Total\"])\n",
    "    anova_out = pd.concat([anova_table[[\"SS\",\"df\",\"MS\",\"F\",\"p_value\"]], total_row])\n",
    "\n",
    "    # Tukey HSD (R2) + CLD\n",
    "    tukey = pairwise_tukeyhsd(endog=df[\"R2\"].values,\n",
    "                              groups=df[\"model\"].astype(str).values,\n",
    "                              alpha=alpha)\n",
    "    cld = compact_letter_display_from_tukey(tukey, MODEL_NAMES)\n",
    "\n",
    "    # Bootstrap CI for mean MSE\n",
    "    boot_rows = []\n",
    "    rng = np.random.default_rng(42)\n",
    "    low_q, high_q = 100*alpha/2, 100*(1-alpha/2)\n",
    "    for m in MODEL_NAMES:\n",
    "        mse_vals = df.loc[df[\"model\"] == m, \"MSE\"].dropna().values\n",
    "        if len(mse_vals) == 0:\n",
    "            mean_mse = lo = hi = np.nan\n",
    "        else:\n",
    "            bs_means = [np.mean(rng.choice(mse_vals, size=len(mse_vals), replace=True))\n",
    "                        for _ in range(bootstrap_n)]\n",
    "            lo, hi = np.percentile(bs_means, [low_q, high_q])\n",
    "            mean_mse = float(np.mean(mse_vals))\n",
    "        boot_rows.append({\"model\": m, \"Mean_MSE\": mean_mse, f\"CI{int(ci_level*100)}_low\": lo, f\"CI{int(ci_level*100)}_high\": hi})\n",
    "    boot_df = pd.DataFrame(boot_rows)\n",
    "\n",
    "    # Summary table\n",
    "    summary_rows = []\n",
    "    for m in MODEL_NAMES:\n",
    "        r2_vals = df.loc[df[\"model\"] == m, \"R2\"].dropna().values\n",
    "        mean_r2 = float(np.mean(r2_vals)) if len(r2_vals) else np.nan\n",
    "        sd_r2 = float(np.std(r2_vals, ddof=1)) if len(r2_vals) > 1 else np.nan\n",
    "        row = {\"Model\": m, \"Mean_R2\": mean_r2, \"SD_R2\": sd_r2, \"Group\": cld.get(m,\"\")}\n",
    "        row.update(boot_df.loc[boot_df[\"model\"]==m].drop(columns=[\"model\"]).to_dict(orient=\"records\")[0])\n",
    "        summary_rows.append(row)\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "    # Save\n",
    "    ci_tag = f\"ci{int(ci_level*100)}\"\n",
    "    OUT = \"statsig_outputs\"\n",
    "    os.makedirs(OUT, exist_ok=True)\n",
    "    shapiro_df.to_csv(os.path.join(OUT, f\"shapiro_{ci_tag}.csv\"), index=False)\n",
    "    levene_df.to_csv(os.path.join(OUT, f\"levene_{ci_tag}.csv\"), index=False)\n",
    "    anova_out.to_csv(os.path.join(OUT, f\"anova_r2_{ci_tag}.csv\"))\n",
    "    summary_df.to_csv(os.path.join(OUT, f\"summary_r2_mse_{ci_tag}.csv\"), index=False)\n",
    "\n",
    "    return {\"summary\": summary_df, \"anova\": anova_out, \"shapiro\": shapiro_df, \"levene\": levene_df, \"raw\": df, \"tukey\": tukey.summary()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_r2_bar_with_groups(summary_df: pd.DataFrame, ci_level: float = CI_LEVEL, save=True):\n",
    "    labels = summary_df[\"Model\"].tolist()\n",
    "    means = summary_df[\"Mean_R2\"].values\n",
    "    groups = summary_df[\"Group\"].tolist()\n",
    "\n",
    "    plt.figure(figsize=(9,5))\n",
    "    plt.bar(labels, means)\n",
    "    for i, g in enumerate(groups):\n",
    "        plt.text(i, means[i] + 0.003, g, ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "    plt.ylabel(\"Mean R2\")\n",
    "    plt.title(\"Mean R2 by Model (Tukey CLD)\")\n",
    "    plt.xticks(rotation=20)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        path = os.path.join(\"statsig_outputs\", f\"r2_bar_groups_ci{int(ci_level*100)}.png\")\n",
    "        plt.savefig(path, dpi=160)\n",
    "        print(\"Saved:\", path)\n",
    "    plt.show()\n",
    "\n",
    "def plot_mse_bootstrap_hist(df_metrics: pd.DataFrame, ci_level: float = CI_LEVEL, bootstrap_n: int = BOOTSTRAP_N, save=True):\n",
    "    rng = np.random.default_rng(42)\n",
    "    for m in MODEL_NAMES:\n",
    "        mse_vals = df_metrics.loc[df_metrics[\"model\"] == m, \"MSE\"].dropna().values\n",
    "        if len(mse_vals) == 0:\n",
    "            continue\n",
    "        bs_means = [np.mean(rng.choice(mse_vals, size=len(mse_vals), replace=True))\n",
    "                    for _ in range(bootstrap_n)]\n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.hist(bs_means, bins=40)\n",
    "        plt.title(f\"Bootstrap Mean MSE — {m}\")\n",
    "        plt.xlabel(\"Mean MSE\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.tight_layout()\n",
    "        if save:\n",
    "            p = os.path.join(\"statsig_outputs\", f\"bootstrap_mse_{m.replace('+','_')}_ci{int(ci_level*100)}.png\")\n",
    "            plt.savefig(p, dpi=160)\n",
    "            print(\"Saved:\", p)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef75b8a1",
   "metadata": {},
   "source": [
    "\n",
    "## Run\n",
    "- Set `METRICS_CSV` to your CSV path and execute.\n",
    "- The notebook will generate tables under `statsig_outputs/` and figures for quick inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75907f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if METRICS_CSV:\n",
    "    df_metrics = load_metrics_from_csv(METRICS_CSV)\n",
    "    print(\"Loaded:\", METRICS_CSV)\n",
    "    out = run_statsig_pipeline(df_metrics, ci_level=CI_LEVEL, bootstrap_n=BOOTSTRAP_N)\n",
    "    display(out[\"summary\"])\n",
    "    display(out[\"anova\"])\n",
    "    display(out[\"shapiro\"])\n",
    "    display(out[\"levene\"])\n",
    "    plot_r2_bar_with_groups(out[\"summary\"], ci_level=CI_LEVEL, save=True)\n",
    "    plot_mse_bootstrap_hist(out[\"raw\"], ci_level=CI_LEVEL, bootstrap_n=BOOTSTRAP_N, save=True)\n",
    "else:\n",
    "    print(\"Set METRICS_CSV to your per-fold results CSV and re-run this cell.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
